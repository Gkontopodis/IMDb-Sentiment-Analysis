# Sentiment Analysis of IMDb

"IMDb dataset contains 25,000 movie reviews along with their associated binary sentiment polarity labels. It is intended to serve as a benchmark for sentiment classification. The dataset is split into train, development and test sets. Each set contains files with negative and positive reviews, one review per line. The overall distribution of labels is roughly balanced."

Before selecting any essential features and building the model, it is important to combine the positive and negative reviews into one set, since they were provided in separated files. Thus for each train, development and test set, a single data frame was created containing both positive and negative reviews. In addition, a new column was added, named 'label', that is a binary variable which describes every single review. Each review was labeled with 0, if it was negative, or 1, if it was positive. It was also necessary, to shuffle the rows, to avoid having all the positive reviews first and all the negatives below. Development set was used to experiment on improving model's accuracy. The overall performance was also evaluated in terms Precision, recall and F-measure, on the test set.

The model aims to predict whether the movie reviews of the test set, are negative or positive, trained by the known reviews. The evaluation of its accuracy will be measured, by comparing the labels predicted by the model with the labels contained in the test set. First the tokens are transformed into features, using the 'Bag of Words' method. This method takes all the possible words or tokens that exist in our dataset, and for each such token, it creates a column that corresponds to that particular word. Thus, a large matrix is created, each row of which corresponds to a specific movie review from our set. If a particular word exists inside the review, the row of the review has a number in the corresponding column of the word, according to the frequency of the word in the sentence. As a result, each review is translated to a large vector that can be processed by the model.

The TfidfVecorizer stands for term frequency and inverse document frequency. It takes the frequency of each term in our set and multiplies it with the inverse frequency of that term in the whole document. Inverse frequency is equal to the logarithm of the total number of reviews, divided by the number of reviews, that this particular term appears. Then it replaces counters in our bag of word representation with these tfitd values and normalises the result row-wise. The rest of the features were passed through TfidfVecorizer as arguments. The min_df is essentially a cutoff threshold that ignores terms that have a document frequency strictly lower than the given 1, targeting on filtering typos or mistakes. In sklearn this argument is passed as a ratio of documents rather than a real valid number of documents. The stop_words argument strips away stop words, like 'the','are','is' etc. These words are unnecessary and useless in predicting whether a sentence contains hate speech or not.

As it was mentioned before, after using TF-IDF values, the result comes with a huge matrix which is extremely sparse. 99.8% of all values in this matrix are zeros. This applies some restrictions on the models that we can use on top of these features. 

The model that is usable for these features is logistic regression. It tries to predict the probability of a review being a positive one, given the features that we gave that model for that particular review. It finds the weight for every feature of that 'Bag of Words' representation, multiplies each TF-IDF value with that weight and passes the sum of all this values through a sigmoid activation function.

Logistic Regression is a linear classification model and since it is linear, it can handle sparse data. It is really fast to train and what is more, the weights that we get after the training can be interpreted.

![Plot](https://github.com/Gkontopodis/IMDb-Sentiment-Analysis/blob/master/Plot.png)

As it can be seen in the graph above, if we have a linear combination that is close to 0, the sigmoid function will output 0.5. So the probability of a review being positive is 0.5 and thus we dont know if it is positive or negative. But if that linear combination in the argument of the sigmoid function starts to become more and more positive, it goes further away from zero. As a result, the probability of a review being positive actually grows really fast. This means that if we get the weight of our features that are positive, then those weights will likely correspond to the words that a positive. And if we take negative weights, they will correspond to the words that are negative like 'disgusting' or 'awful'.

After testing the model with the development set, we conducted additional experiments by choosing our features differently, aiming to improve model's efficiency. In fact 'Bag of Words' method causes some problems in our text representation. The first one is that we lose word order, because we can actually shuffle over words, and the representation will stay the same. Thus, it is necessary to look at token pairs. This approach is called as extracting 2-grams. The idea is to create extra columns in the matrix with the vectorized words, that correspond to token pairs in order to preserve some local word order that will help us to analyze this text better. The 2-grams extraction is implemented through TfidfVecorizer as an argument (ngram_range=(1,2)). The TfidfVecorizer filters out low frequency pairs, like typos, and high frequency pairs, like articles or prepositions.

Once we trained the Logistic Regression model with paired tokens and TF-IDF values, its performance was slightly improved. The addition of the 2-grams provided 1.5% improvement in the model's accuracy. As it can be seen in the table below, the model's score is now approximately 90% on the test set.

![After](https://github.com/Gkontopodis/IMDb-Sentiment-Analysis/blob/master/After.png)

It is true that the model could be potentially improved more in the future. One idea could be, to play around with tokenization. In reviews people usually use different characters like emojis, smiling or angry faces written with text or bunch of exclamation marks. We could actually take into account these sequences, manipulate them as different tokens and introduce them to our model. Another idea could be to apply stemming or lemmatization, or try different models like SVM or Naive Bayes that can handle sparse features. Finally, we can even throw 'Bag of Words' method away and use deep learning techniques, to squeeze the maximum accuracy from this model.
